{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "from rtpt import RTPT\n",
    "from tqdm.notebook import tqdm\n",
    "import h5py\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.nn import  CrossEntropyLoss, MSELoss\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "from main_config import main_config\n",
    "\n",
    "from gym_env import RBCEnv\n",
    "from nn.ppo_nn import CustomActorCriticPolicy\n",
    "from train.utils import create_hdf5_generator\n",
    "\n",
    "from gym.spaces import Space, Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H5_TRAIN = \"..\\\\data\\\\top3-partial-flip-train.hdf5\"\n",
    "# H5_VAL = \"..\\\\data\\\\top3-partial-flip-val.hdf5\"\n",
    "# H5_TEST = \"..\\\\data\\\\top3-partial-flip-test.hdf5\"\n",
    "\n",
    "H5_TRAIN = main_config[\"train_dir\"]\n",
    "H5_VAL = main_config[\"val_dir\"]\n",
    "H5_TEST = main_config[\"test_dir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "file = h5py.File(H5_TRAIN)\n",
    "train_data_size = file['data'].shape[0]\n",
    "file = h5py.File(H5_VAL)\n",
    "val_data_size = file['data'].shape[0]\n",
    "train_hdf5_generator = create_hdf5_generator(H5_TRAIN, batch_size)\n",
    "val_hdf5_generator = create_hdf5_generator(H5_VAL, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, train_loader, val_loader, criterion, opt_func = SGD):\n",
    "    rtpt = RTPT(name_initials='AM', experiment_name='sense-pre-training', max_iterations=epochs)\n",
    "    rtpt.start()\n",
    "    best_val_loss = np.inf\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr, weight_decay=0.01)\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        with tqdm(train_loader,  unit='batch', total = train_data_size // batch_size) as tepoch:\n",
    "            for data, labels in tepoch: \n",
    "                # print('data shape ', data.shape)\n",
    "                # print('labels shape ', labels.shape)\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "                if labels.shape[0] < batch_size or data.shape[0] < batch_size: \n",
    "                    break\n",
    "                # labels = labels.to(torch.float).unsqueeze(-1) # MSE\n",
    "                labels = labels.to(torch.long) # CrossEntropyLoss\n",
    "                # converting the data into GPU format\n",
    "                if torch.cuda.is_available():\n",
    "                    data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "                loss = model.training_step(criterion, data, labels)\n",
    "                train_losses.append(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        outputs = []\n",
    "        with tqdm(val_loader, unit='batch', total = val_data_size // batch_size) as vepoch:\n",
    "            for data, labels in vepoch:\n",
    "                if labels.shape[0] < batch_size or data.shape[0] < batch_size: \n",
    "                    break\n",
    "                # labels = labels.to(torch.float).unsqueeze(-1) # MSE\n",
    "                # labels = labels.to(torch.long) # CrossEntropyLoss\n",
    "                # converting the data into GPU format\n",
    "                if torch.cuda.is_available():\n",
    "                    data, labels = data.cuda(), labels.cuda()\n",
    "                outputs.append(model.validation_step(criterion, data, labels))\n",
    "        result = model.validation_epoch_end(outputs)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "        \n",
    "        if result['val_loss'] < best_val_loss: \n",
    "            val_loss = result['val_loss']\n",
    "            print(f'Validation Loss Decreased({best_val_loss}--->{val_loss}) \\t Saving The Model')\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model, '/root/rbc/models/pretrain_model.pth')\n",
    "\n",
    "        rtpt.step()\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "env = RBCEnv()\n",
    "    # check_env(env=env)\n",
    "\n",
    "model = PPO(CustomActorCriticPolicy, env, verbose = 1)\n",
    "policy = model.policy\n",
    "\n",
    "opt_func = Adam\n",
    "lr = 0.001\n",
    "criterion = CrossEntropyLoss()\n",
    "# criterion = MSELoss()\n",
    "# criterion = DiceLoss()\n",
    "num_epochs = 20\n",
    "\n",
    "# check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    policy = policy.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "history = fit(num_epochs, lr, policy, train_hdf5_generator, val_hdf5_generator, criterion, opt_func)\n",
    "\n",
    "# model.learn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aniss\\OneDrive\\Dokumente\\Uni\\Semester4\\RBC\\RBC-Agent\\train\\policy_pretraining.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aniss/OneDrive/Dokumente/Uni/Semester4/RBC/RBC-Agent/train/policy_pretraining.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mLoss vs. No. of epochs\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aniss/OneDrive/Dokumente/Uni/Semester4/RBC/RBC-Agent/train/policy_pretraining.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aniss/OneDrive/Dokumente/Uni/Semester4/RBC/RBC-Agent/train/policy_pretraining.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m plot_accuracies(history)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aniss/OneDrive/Dokumente/Uni/Semester4/RBC/RBC-Agent/train/policy_pretraining.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m plot_losses(history)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_accuracies(history):\n",
    "    \"\"\" Plot the history of accuracies\"\"\"\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_losses(history):\n",
    "    \"\"\" Plot the losses in each epoch\"\"\"\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs')\n",
    "    plt.show()\n",
    "    \n",
    "plot_accuracies(history)\n",
    "\n",
    "plot_losses(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('rbc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "334571f43833167cff2a32fc3fb1a5df84c2106c1727de884da5357de05be83f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
